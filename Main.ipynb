{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "kld_reg= 1\n",
    "adl_reg=1\n",
    "\n",
    "fdim=16\n",
    "zdim=16\n",
    "sigma=1.3\n",
    "past_length=8\n",
    "future_length=12\n",
    "data_scale=170\n",
    "enc_past_size=(past_length*2,512,256,fdim)\n",
    "enc_dest_size=(2,8,16,fdim)\n",
    "enc_latent_size=(2*fdim,8,50,2*zdim)\n",
    "dec_size=(fdim + zdim,1024,512,1024,2)\n",
    "predictor_size=(2*fdim,1024,512,256,2*(future_length-1))\n",
    "learning_rate=0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file_path: str):\n",
    "  npz = np.load(file_path, allow_pickle=True)\n",
    "  return npz['observations'], npz['obs_speed'], npz['targets'], npz[\n",
    "      'target_speed'], npz['mean'], npz['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "  def __init__(self, input_dim, output_size, name=None):\n",
    "    super(Dense, self).__init__(name=name)\n",
    "    self.w = tf.Variable(tf.random.uniform([input_dim, output_size],-(1.0/input_dim)**0.5,(1.0/input_dim)**0.5 ),name='w',dtype=tf.float32)\n",
    "    self.b = tf.Variable(tf.random.uniform([output_size],-(1.0/input_dim)**0.5,(1.0/input_dim)**0.5 ), name='b',dtype=tf.float32)\n",
    "  def __call__(self, x):\n",
    "    x = tf.constant(x,dtype=tf.float32)\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    return tf.nn.relu(y)\n",
    "\n",
    "class FullyConnectedNeuralNet(tf.Module):\n",
    "  def __init__(self,sizes, name=None):\n",
    "    super(FullyConnectedNeuralNet, self).__init__(name=name)\n",
    "    self.layers = []\n",
    "    with self.name_scope:\n",
    "      for i in range(len(sizes)-1):\n",
    "        self.layers.append(Dense(input_dim=sizes[i], output_size=sizes[i+1]))\n",
    "  @tf.Module.with_name_scope\n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(tf.Module):\n",
    "  def __init__(self,name=None):\n",
    "    super(MainModel, self).__init__(name=name)\n",
    "\n",
    "    self.zdim = zdim\n",
    "    self.sigma = sigma\n",
    "\n",
    "    self.pastEncoder = FullyConnectedNeuralNet(enc_past_size)\n",
    "\n",
    "    self.destEncoder = FullyConnectedNeuralNet(enc_dest_size)\n",
    "\n",
    "    self.latentDistributionEncoder = FullyConnectedNeuralNet(enc_latent_size)\n",
    "\n",
    "    self.latentDistributionDecoder = FullyConnectedNeuralNet(dec_size)\n",
    "\n",
    "    self.predictorNetwork = FullyConnectedNeuralNet(predictor_size)\n",
    "\n",
    "  def forward(self, x, dest = []):\n",
    "\n",
    "    if len(dest):\n",
    "        self.training=True\n",
    "    else:\n",
    "        self.training=False\n",
    "        \n",
    "    # encode\n",
    "    traj_past_ftr = self.pastEncoder(x)\n",
    "    #print(f\"ftraj max {ftraj.numpy().max()}\")\n",
    "    if not self.training:\n",
    "        z = tf.random.normal((x.shape[0], self.zdim),0,self.sigma)\n",
    "\n",
    "    else:\n",
    "        dest_ftr = self.destEncoder(dest)\n",
    "        #print(f\"dest_features Max {dest_features.numpy().max()}\")\n",
    "\n",
    "        concat_ftr = tf.concat((traj_past_ftr, dest_ftr), axis = 1)\n",
    "        latent =  self.latentDistributionEncoder(concat_ftr)\n",
    "        mu = latent[:, 0:self.zdim] # 2-d array\n",
    "        logvar = latent[:, self.zdim:] # 2-d array\n",
    "\n",
    "        var = tf.math.exp(logvar*0.5)\n",
    "        #print(f\"var {var}\")\n",
    "        eps = tf.random.normal(var.shape)\n",
    "        z = eps*var + mu\n",
    "        #print(f\"z -> {z}\")\n",
    "\n",
    "\n",
    "    latentDistributionDecoder_input = tf.concat((traj_past_ftr, z), axis = 1)\n",
    "    generated_dest = self.latentDistributionDecoder(latentDistributionDecoder_input)\n",
    "    \n",
    "    if self.training:\n",
    "        generated_dest_ftr = self.destEncoder(generated_dest)\n",
    "        prediction_ftr = tf.concat((traj_past_ftr, generated_dest_ftr), axis = 1)\n",
    "        pred_future = self.predictorNetwork(prediction_ftr)\n",
    "        \n",
    "        return (generated_dest, mu, logvar, pred_future)\n",
    "    else:\n",
    "        return generated_dest\n",
    "\n",
    "  def predict(self, past, generated_dest):\n",
    "        \n",
    "    traj_past_ftr = self.pastEncoder(past)\n",
    "    generated_dest_ftr = self.destEncoder(generated_dest)\n",
    "    prediction_ftr = tf.concat((traj_past_ftr, generated_dest_ftr), axis = 1)\n",
    "    future_traj = self.predictorNetwork(prediction_ftr)\n",
    "    return future_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(dest, dest_rec, mean, log_var, future, future_rec):\n",
    "    \n",
    "    rcl = tf.math.reduce_mean(tf.keras.metrics.mean_squared_error(dest, dest_rec))\n",
    "    adl = tf.math.reduce_mean(tf.keras.metrics.mean_squared_error(future, future_rec))\n",
    "\n",
    "    kld = -0.5 * tf.math.reduce_sum(1 + log_var - mean**2 - tf.math.exp(log_var))\n",
    "\n",
    "    return rcl, kld, adl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X,batchSize):\n",
    "    start = random.randint(0, len(X)-batchSize)\n",
    "    return X[start:start+batchSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(trajx,model,optimizer):\n",
    "    train_loss = 0\n",
    "    total_rcl, total_kld, total_adl = 0, 0, 0\n",
    "    \n",
    "    traj = trajx - trajx[:, :1, :]\n",
    "    traj *= data_scale\n",
    "\n",
    "    x = traj[:, :past_length, :]\n",
    "    y = traj[:, past_length:, :]\n",
    "\n",
    "    x = x.reshape(-1, x.shape[1]*x.shape[2]) # (x,y,x,y ... )\n",
    "    dest = y[:, -1, :]\n",
    "    future = y[:, :-1, :].reshape(y.shape[0],-1)\n",
    "                \n",
    "    #x.astype(np.float64)\n",
    "    #print(f\"x max -> {x.max()}\")\n",
    "\n",
    "    with tf.GradientTape() as tape:\n",
    "        x=tf.constant(x,dtype=tf.float32)\n",
    "        tape.watch(x)\n",
    "        dest_rec, mu, var, future_rec = model.forward(x, dest=dest)\n",
    "        #print(f\"dest_recon {dest_recon}\")\n",
    "        #print(f\"mu {mu}\")\n",
    "        #print(f\"var {var}\")\n",
    "        #print(f\"interpolated_future {interpolated_future}\")\n",
    "                    \n",
    "        rcl, kld, adl = calculate_loss(dest, dest_rec, mu, var, future, future_rec)\n",
    "                    \n",
    "        loss = rcl + kld * kld_reg + adl * adl_reg\n",
    "        grad_sub = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad_sub, model.trainable_variables))\n",
    "                    \n",
    "        #print(f\"total Loss {loss}\")\n",
    "        #print(f\"rcl Loss {rcl}\")\n",
    "        #print(f\"kld Loss {kld}\")\n",
    "        #print(f\"adl Loss {adl}\")\n",
    "    train_loss+=loss\n",
    "    total_rcl+=rcl\n",
    "    total_kld+=kld\n",
    "    total_adl+=adl\n",
    "    return train_loss, total_rcl, total_kld, total_adl\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(trajx, model, best_of_n = 1):\n",
    "    \n",
    "    traj = trajx - trajx[:, :1, :]\n",
    "    traj *= data_scale\n",
    "\n",
    "    x = traj[:, :past_length, :]\n",
    "    y = traj[:, past_length:, :]\n",
    "\n",
    "    x = x.reshape(-1, x.shape[1]*x.shape[2])\n",
    "\n",
    "    dest = y[:, -1, :]\n",
    "    \n",
    "    destination_errors = []\n",
    "    dectination_recs = []\n",
    "    \n",
    "    for _ in range(best_of_n):\n",
    "        x=tf.constant(x,dtype=tf.float32)\n",
    "        dest_rec = model.forward(x)\n",
    "        dectination_recs.append(np.array(dest_rec))\n",
    "\n",
    "        error = np.linalg.norm(dest_rec - dest, axis = 1)\n",
    "        destination_errors.append(error)\n",
    "\n",
    "    destination_errors = np.array(destination_errors)\n",
    "    dectination_recs = np.array(dectination_recs)\n",
    "    # average error\n",
    "    avg_dest_error = np.mean(destination_errors)\n",
    "\n",
    "    indices = np.argmin(destination_errors, axis = 0)\n",
    "\n",
    "    best_dest = dectination_recs[indices,np.arange(x.shape[0]),  :]\n",
    "\n",
    "    # taking the minimum error out of all guess\n",
    "    dest_error = np.mean(np.min(destination_errors, axis = 0))\n",
    "\n",
    "    future_dest = model.predict(x, best_dest)\n",
    "    # final overall prediction\n",
    "    predicted_future = np.concatenate((future_dest, best_dest), axis = 1)\n",
    "    predicted_future = np.reshape(predicted_future, (-1, future_length, 2))\n",
    "    # ADE error\n",
    "    overall_error = np.mean(np.linalg.norm(y - predicted_future, axis = 2))\n",
    "\n",
    "    overall_error /= data_scale\n",
    "    dest_error /= data_scale\n",
    "    avg_dest_error /= data_scale\n",
    "    print('Test time error in destination best: {:0.3f} and mean: {:0.3f}'.format(dest_error, avg_dest_error))\n",
    "    print('Test time error overall (ADE) best: {:0.3f}'.format(overall_error))\n",
    "\n",
    "    return overall_error, dest_error, avg_dest_error\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    observations, _, targets, _, _, _ = loadData('./data/eth/eth_train.npz')\n",
    "    train_dataset = np.concatenate([observations, targets], axis=1)\n",
    "    observations, _, targets, _, _, _ = loadData('./data/eth/eth_test.npz')\n",
    "    test_dataset = np.concatenate([observations, targets], axis=1)\n",
    "    \n",
    "    epochs = 8\n",
    "    batchSize=100\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    model=MainModel()\n",
    "    N=20\n",
    "    best_test_loss = 50 # start saving after this threshold\n",
    "    best_endpoint_loss = 50\n",
    "    for epo in range(epochs):\n",
    "            print(f\"Epoch : {epo+1}\")\n",
    "            for it in range(int(len(train_dataset)/batchSize)):\n",
    "                trajx_train = next_batch(train_dataset,batchSize)\n",
    "                trajx_test = next_batch(test_dataset,len(test_dataset))\n",
    "                \n",
    "                train_loss, rcl, kld, adl = train(train_dataset, model,optimizer)\n",
    "                test_loss, final_point_loss_best, final_point_loss_avg = test(trajx_test, model, best_of_n = N)\n",
    "                \n",
    "                if best_test_loss > test_loss:\n",
    "                    print(\"Epoch: \", epo)\n",
    "                    print('################## BEST PERFORMANCE {:0.2f} ########'.format(test_loss))\n",
    "                    best_test_loss = test_loss\n",
    "                \"\"\"\"\n",
    "                if best_test_loss < 10.25:\n",
    "                    save_path = './content/trained.pt'\n",
    "                    torch.save({\n",
    "                              'hyper_params': hyper_params,\n",
    "                              'model_state_dict': model.state_dict(),\n",
    "                              'optimizer_state_dict': optimizer.state_dict()\n",
    "                          }, save_path)\n",
    "                    print(\"Saved model to:\\n{}\".format(save_path))\n",
    "                \"\"\"\n",
    "\n",
    "                if final_point_loss_best < best_endpoint_loss:\n",
    "                    best_endpoint_loss = final_point_loss_best\n",
    "\n",
    "                print(\"Train Loss\", train_loss)\n",
    "                print(\"RCL\", rcl)\n",
    "                print(\"KLD\", kld)\n",
    "                print(\"ADL\", adl)\n",
    "                print(\"Test ADE\", test_loss)\n",
    "                print(\"Test Average FDE (Across  all samples)\", final_point_loss_avg)\n",
    "                print(\"Test Min FDE\", final_point_loss_best)\n",
    "                print(\"Test Best ADE Loss So Far (N = {})\".format(N), best_test_loss)\n",
    "                print(\"Test Best Min FDE (N = {})\".format(N), best_endpoint_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1\n",
      "Test time error in destination best: 6.511 and mean: 6.511\n",
      "Test time error overall (ADE) best: 4.983\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.98 ########\n",
      "Train Loss tf.Tensor(22118875000.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(422402.8, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(22118236000.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(216217.98, shape=(), dtype=float32)\n",
      "Test ADE 4.983260532172781\n",
      "Test Average FDE (Across  all samples) 6.511101217830882\n",
      "Test Min FDE 6.510986328125\n",
      "Test Best ADE Loss So Far (N = 20) 4.983260532172781\n",
      "Test Best Min FDE (N = 20) 6.510986328125\n",
      "Test time error in destination best: 6.512 and mean: 6.512\n",
      "Test time error overall (ADE) best: 4.982\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.98 ########\n",
      "Train Loss tf.Tensor(1818681100.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(421635.06, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(1818043300.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(216151.47, shape=(), dtype=float32)\n",
      "Test ADE 4.982313559228841\n",
      "Test Average FDE (Across  all samples) 6.5123571059283085\n",
      "Test Min FDE 6.512207749310662\n",
      "Test Best ADE Loss So Far (N = 20) 4.982313559228841\n",
      "Test Best Min FDE (N = 20) 6.510986328125\n",
      "Test time error in destination best: 6.514 and mean: 6.514\n",
      "Test time error overall (ADE) best: 4.981\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.98 ########\n",
      "Train Loss tf.Tensor(416820770.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(421439.56, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(416183230.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(216081.84, shape=(), dtype=float32)\n",
      "Test ADE 4.98111856830212\n",
      "Test Average FDE (Across  all samples) 6.514065372242647\n",
      "Test Min FDE 6.5138643152573525\n",
      "Test Best ADE Loss So Far (N = 20) 4.98111856830212\n",
      "Test Best Min FDE (N = 20) 6.510986328125\n",
      "Test time error in destination best: 6.513 and mean: 6.513\n",
      "Test time error overall (ADE) best: 4.979\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.98 ########\n",
      "Train Loss tf.Tensor(141332380.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(421347.75, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(140695040.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(215998.14, shape=(), dtype=float32)\n",
      "Test ADE 4.979266509215773\n",
      "Test Average FDE (Across  all samples) 6.513253245634191\n",
      "Test Min FDE 6.512719008501838\n",
      "Test Best ADE Loss So Far (N = 20) 4.979266509215773\n",
      "Test Best Min FDE (N = 20) 6.510986328125\n",
      "Test time error in destination best: 6.506 and mean: 6.506\n",
      "Test time error overall (ADE) best: 4.977\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.98 ########\n",
      "Train Loss tf.Tensor(60786484.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(420958.22, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(60149636.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(215889.05, shape=(), dtype=float32)\n",
      "Test ADE 4.97651041751232\n",
      "Test Average FDE (Across  all samples) 6.506471880744486\n",
      "Test Min FDE 6.505791159237132\n",
      "Test Best ADE Loss So Far (N = 20) 4.97651041751232\n",
      "Test Best Min FDE (N = 20) 6.505791159237132\n",
      "Test time error in destination best: 6.498 and mean: 6.499\n",
      "Test time error overall (ADE) best: 4.973\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.97 ########\n",
      "Train Loss tf.Tensor(30425708.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(420180.03, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(29789784.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(215744.77, shape=(), dtype=float32)\n",
      "Test ADE 4.973032643881418\n",
      "Test Average FDE (Across  all samples) 6.499083036534927\n",
      "Test Min FDE 6.498258702895221\n",
      "Test Best ADE Loss So Far (N = 20) 4.973032643881418\n",
      "Test Best Min FDE (N = 20) 6.498258702895221\n",
      "Test time error in destination best: 6.489 and mean: 6.490\n",
      "Test time error overall (ADE) best: 4.969\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.97 ########\n",
      "Train Loss tf.Tensor(17133750.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(419503.75, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(16498678.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(215568.31, shape=(), dtype=float32)\n",
      "Test ADE 4.968679578469079\n",
      "Test Average FDE (Across  all samples) 6.490273868336397\n",
      "Test Min FDE 6.489345415900735\n",
      "Test Best ADE Loss So Far (N = 20) 4.968679578469079\n",
      "Test Best Min FDE (N = 20) 6.489345415900735\n",
      "Test time error in destination best: 6.484 and mean: 6.485\n",
      "Test time error overall (ADE) best: 4.964\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.96 ########\n",
      "Train Loss tf.Tensor(10555641.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(418185.56, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(9922106.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(215349.39, shape=(), dtype=float32)\n",
      "Test ADE 4.964327990704035\n",
      "Test Average FDE (Across  all samples) 6.485093778722426\n",
      "Test Min FDE 6.484191176470588\n",
      "Test Best ADE Loss So Far (N = 20) 4.964327990704035\n",
      "Test Best Min FDE (N = 20) 6.484191176470588\n",
      "Test time error in destination best: 6.473 and mean: 6.474\n",
      "Test time error overall (ADE) best: 4.959\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.96 ########\n",
      "Train Loss tf.Tensor(7005929.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(416760.34, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(6374074.0, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(215094.88, shape=(), dtype=float32)\n",
      "Test ADE 4.959037594852174\n",
      "Test Average FDE (Across  all samples) 6.4740220013786764\n",
      "Test Min FDE 6.472957835477941\n",
      "Test Best ADE Loss So Far (N = 20) 4.959037594852174\n",
      "Test Best Min FDE (N = 20) 6.472957835477941\n",
      "Test time error in destination best: 6.453 and mean: 6.455\n",
      "Test time error overall (ADE) best: 4.952\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.95 ########\n",
      "Train Loss tf.Tensor(4926933.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(415298.4, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(4296830.5, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(214804.61, shape=(), dtype=float32)\n",
      "Test ADE 4.952007738157689\n",
      "Test Average FDE (Across  all samples) 6.454564711626838\n",
      "Test Min FDE 6.45338134765625\n",
      "Test Best ADE Loss So Far (N = 20) 4.952007738157689\n",
      "Test Best Min FDE (N = 20) 6.45338134765625\n",
      "Test time error in destination best: 6.426 and mean: 6.428\n",
      "Test time error overall (ADE) best: 4.943\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.94 ########\n",
      "Train Loss tf.Tensor(3645859.8, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(413244.4, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(3018161.5, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(214453.81, shape=(), dtype=float32)\n",
      "Test ADE 4.943055919424728\n",
      "Test Average FDE (Across  all samples) 6.427871524586397\n",
      "Test Min FDE 6.426264504825368\n",
      "Test Best ADE Loss So Far (N = 20) 4.943055919424728\n",
      "Test Best Min FDE (N = 20) 6.426264504825368\n",
      "Test time error in destination best: 6.402 and mean: 6.404\n",
      "Test time error overall (ADE) best: 4.934\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.93 ########\n",
      "Train Loss tf.Tensor(2823216.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(411008.84, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(2198156.2, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(214051.02, shape=(), dtype=float32)\n",
      "Test ADE 4.933581254565491\n",
      "Test Average FDE (Across  all samples) 6.404172650505514\n",
      "Test Min FDE 6.402436379825367\n",
      "Test Best ADE Loss So Far (N = 20) 4.933581254565491\n",
      "Test Best Min FDE (N = 20) 6.402436379825367\n",
      "Test time error in destination best: 6.380 and mean: 6.382\n",
      "Test time error overall (ADE) best: 4.923\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.92 ########\n",
      "Train Loss tf.Tensor(2275382.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(408447.8, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(1653338.2, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(213596.02, shape=(), dtype=float32)\n",
      "Test ADE 4.923180078090537\n",
      "Test Average FDE (Across  all samples) 6.381609748391544\n",
      "Test Min FDE 6.379742790670956\n",
      "Test Best ADE Loss So Far (N = 20) 4.923180078090537\n",
      "Test Best Min FDE (N = 20) 6.379742790670956\n",
      "Test time error in destination best: 6.348 and mean: 6.350\n",
      "Test time error overall (ADE) best: 4.911\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.91 ########\n",
      "Train Loss tf.Tensor(1909642.8, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(405650.22, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(1290919.6, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(213072.89, shape=(), dtype=float32)\n",
      "Test ADE 4.910897563854539\n",
      "Test Average FDE (Across  all samples) 6.349863568474265\n",
      "Test Min FDE 6.347784064797795\n",
      "Test Best ADE Loss So Far (N = 20) 4.910897563854539\n",
      "Test Best Min FDE (N = 20) 6.347784064797795\n",
      "Test time error in destination best: 6.304 and mean: 6.306\n",
      "Test time error overall (ADE) best: 4.896\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.90 ########\n",
      "Train Loss tf.Tensor(1656073.8, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(402481.56, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(1041122.8, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(212469.44, shape=(), dtype=float32)\n",
      "Test ADE 4.8962337162726195\n",
      "Test Average FDE (Across  all samples) 6.306303854549633\n",
      "Test Min FDE 6.3038847081801475\n",
      "Test Best ADE Loss So Far (N = 20) 4.8962337162726195\n",
      "Test Best Min FDE (N = 20) 6.3038847081801475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time error in destination best: 6.252 and mean: 6.255\n",
      "Test time error overall (ADE) best: 4.878\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.88 ########\n",
      "Train Loss tf.Tensor(1473404.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(398842.72, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(862789.44, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(211771.83, shape=(), dtype=float32)\n",
      "Test ADE 4.878467717677733\n",
      "Test Average FDE (Across  all samples) 6.254861988740809\n",
      "Test Min FDE 6.252130485983455\n",
      "Test Best ADE Loss So Far (N = 20) 4.878467717677733\n",
      "Test Best Min FDE (N = 20) 6.252130485983455\n",
      "Test time error in destination best: 6.196 and mean: 6.199\n",
      "Test time error overall (ADE) best: 4.857\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.86 ########\n",
      "Train Loss tf.Tensor(1337668.1, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(394844.16, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(731861.1, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(210962.86, shape=(), dtype=float32)\n",
      "Test ADE 4.857055440823538\n",
      "Test Average FDE (Across  all samples) 6.198851821001838\n",
      "Test Min FDE 6.195856071920955\n",
      "Test Best ADE Loss So Far (N = 20) 4.857055440823538\n",
      "Test Best Min FDE (N = 20) 6.195856071920955\n",
      "Test time error in destination best: 6.135 and mean: 6.138\n",
      "Test time error overall (ADE) best: 4.832\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.83 ########\n",
      "Train Loss tf.Tensor(1233044.2, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(390309.47, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(632714.06, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(210020.75, shape=(), dtype=float32)\n",
      "Test ADE 4.832317004678924\n",
      "Test Average FDE (Across  all samples) 6.137952378216911\n",
      "Test Min FDE 6.1346478630514705\n",
      "Test Best ADE Loss So Far (N = 20) 4.832317004678924\n",
      "Test Best Min FDE (N = 20) 6.1346478630514705\n",
      "Test time error in destination best: 6.065 and mean: 6.068\n",
      "Test time error overall (ADE) best: 4.804\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.80 ########\n",
      "Train Loss tf.Tensor(1149466.8, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(385292.8, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(555235.06, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(208938.94, shape=(), dtype=float32)\n",
      "Test ADE 4.803579678777455\n",
      "Test Average FDE (Across  all samples) 6.06829833984375\n",
      "Test Min FDE 6.064695111443014\n",
      "Test Best ADE Loss So Far (N = 20) 4.803579678777455\n",
      "Test Best Min FDE (N = 20) 6.064695111443014\n",
      "Test time error in destination best: 5.982 and mean: 5.986\n",
      "Test time error overall (ADE) best: 4.769\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.77 ########\n",
      "Train Loss tf.Tensor(1081212.4, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(379930.9, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(493602.38, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(207679.1, shape=(), dtype=float32)\n",
      "Test ADE 4.7694387428868525\n",
      "Test Average FDE (Across  all samples) 5.986053107766544\n",
      "Test Min FDE 5.982083309397978\n",
      "Test Best ADE Loss So Far (N = 20) 4.7694387428868525\n",
      "Test Best Min FDE (N = 20) 5.982083309397978\n",
      "Test time error in destination best: 5.887 and mean: 5.892\n",
      "Test time error overall (ADE) best: 4.728\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.73 ########\n",
      "Train Loss tf.Tensor(1024150.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(374062.62, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(443888.8, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(206198.56, shape=(), dtype=float32)\n",
      "Test ADE 4.728362045379202\n",
      "Test Average FDE (Across  all samples) 5.891663674747242\n",
      "Test Min FDE 5.88721098058364\n",
      "Test Best ADE Loss So Far (N = 20) 4.728362045379202\n",
      "Test Best Min FDE (N = 20) 5.88721098058364\n",
      "Test time error in destination best: 5.785 and mean: 5.790\n",
      "Test time error overall (ADE) best: 4.680\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.68 ########\n",
      "Train Loss tf.Tensor(975504.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(367787.66, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(403247.22, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(204469.12, shape=(), dtype=float32)\n",
      "Test ADE 4.679762606922904\n",
      "Test Average FDE (Across  all samples) 5.7898584702435665\n",
      "Test Min FDE 5.785137221392463\n",
      "Test Best ADE Loss So Far (N = 20) 4.679762606922904\n",
      "Test Best Min FDE (N = 20) 5.785137221392463\n",
      "Test time error in destination best: 5.679 and mean: 5.684\n",
      "Test time error overall (ADE) best: 4.623\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.62 ########\n",
      "Train Loss tf.Tensor(933149.2, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(361310.8, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(369364.06, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(202474.31, shape=(), dtype=float32)\n",
      "Test ADE 4.623068423203711\n",
      "Test Average FDE (Across  all samples) 5.684036075367647\n",
      "Test Min FDE 5.678854908662684\n",
      "Test Best ADE Loss So Far (N = 20) 4.623068423203711\n",
      "Test Best Min FDE (N = 20) 5.678854908662684\n",
      "Test time error in destination best: 5.571 and mean: 5.576\n",
      "Test time error overall (ADE) best: 4.558\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.56 ########\n",
      "Train Loss tf.Tensor(895515.25, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(354635.56, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(340678.34, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(200201.39, shape=(), dtype=float32)\n",
      "Test ADE 4.557798456350436\n",
      "Test Average FDE (Across  all samples) 5.576464484719669\n",
      "Test Min FDE 5.570824477251838\n",
      "Test Best ADE Loss So Far (N = 20) 4.557798456350436\n",
      "Test Best Min FDE (N = 20) 5.570824477251838\n",
      "Test time error in destination best: 5.462 and mean: 5.468\n",
      "Test time error overall (ADE) best: 4.484\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.48 ########\n",
      "Train Loss tf.Tensor(861804.1, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(347909.56, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(316243.06, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(197651.48, shape=(), dtype=float32)\n",
      "Test ADE 4.483692936697499\n",
      "Test Average FDE (Across  all samples) 5.467812571806066\n",
      "Test Min FDE 5.461589499080882\n",
      "Test Best ADE Loss So Far (N = 20) 4.483692936697499\n",
      "Test Best Min FDE (N = 20) 5.461589499080882\n",
      "Test time error in destination best: 5.352 and mean: 5.359\n",
      "Test time error overall (ADE) best: 4.401\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.40 ########\n",
      "Train Loss tf.Tensor(831262.4, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(341303.9, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(295100.94, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(194857.47, shape=(), dtype=float32)\n",
      "Test ADE 4.40084985470982\n",
      "Test Average FDE (Across  all samples) 5.358650476792279\n",
      "Test Min FDE 5.351581528607537\n",
      "Test Best ADE Loss So Far (N = 20) 4.40084985470982\n",
      "Test Best Min FDE (N = 20) 5.351581528607537\n",
      "Test time error in destination best: 5.241 and mean: 5.249\n",
      "Test time error overall (ADE) best: 4.310\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.31 ########\n",
      "Train Loss tf.Tensor(803552.7, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(334926.75, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(276737.16, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(191888.83, shape=(), dtype=float32)\n",
      "Test ADE 4.309918631726601\n",
      "Test Average FDE (Across  all samples) 5.249260756548713\n",
      "Test Min FDE 5.241411635454964\n",
      "Test Best ADE Loss So Far (N = 20) 4.309918631726601\n",
      "Test Best Min FDE (N = 20) 5.241411635454964\n",
      "Test time error in destination best: 5.133 and mean: 5.141\n",
      "Test time error overall (ADE) best: 4.213\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.21 ########\n",
      "Train Loss tf.Tensor(778395.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(328815.22, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(260726.27, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(188853.53, shape=(), dtype=float32)\n",
      "Test ADE 4.212510037438891\n",
      "Test Average FDE (Across  all samples) 5.141161032284008\n",
      "Test Min FDE 5.1326013901654415\n",
      "Test Best ADE Loss So Far (N = 20) 4.212510037438891\n",
      "Test Best Min FDE (N = 20) 5.1326013901654415\n",
      "Test time error in destination best: 5.029 and mean: 5.038\n",
      "Test time error overall (ADE) best: 4.111\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.11 ########\n",
      "Train Loss tf.Tensor(755700.2, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(323068.2, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(246724.36, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(185907.61, shape=(), dtype=float32)\n",
      "Test ADE 4.111491272497479\n",
      "Test Average FDE (Across  all samples) 5.0379426843979775\n",
      "Test Min FDE 5.028922047334559\n",
      "Test Best ADE Loss So Far (N = 20) 4.111491272497479\n",
      "Test Best Min FDE (N = 20) 5.028922047334559\n",
      "Test time error in destination best: 4.932 and mean: 4.941\n",
      "Test time error overall (ADE) best: 4.012\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 4.01 ########\n",
      "Train Loss tf.Tensor(735687.4, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(317928.38, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(234502.6, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(183256.36, shape=(), dtype=float32)\n",
      "Test ADE 4.011890139545949\n",
      "Test Average FDE (Across  all samples) 4.941296027688419\n",
      "Test Min FDE 4.931567023782169\n",
      "Test Best ADE Loss So Far (N = 20) 4.011890139545949\n",
      "Test Best Min FDE (N = 20) 4.931567023782169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test time error in destination best: 4.839 and mean: 4.849\n",
      "Test time error overall (ADE) best: 3.919\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 3.92 ########\n",
      "Train Loss tf.Tensor(717709.75, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(313058.62, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(223614.06, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(181037.1, shape=(), dtype=float32)\n",
      "Test ADE 3.9194677895605476\n",
      "Test Average FDE (Across  all samples) 4.849391802619485\n",
      "Test Min FDE 4.838509952320772\n",
      "Test Best ADE Loss So Far (N = 20) 3.9194677895605476\n",
      "Test Best Min FDE (N = 20) 4.838509952320772\n",
      "Test time error in destination best: 4.743 and mean: 4.754\n",
      "Test time error overall (ADE) best: 3.838\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 3.84 ########\n",
      "Train Loss tf.Tensor(701472.1, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(308216.1, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(213987.28, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(179268.78, shape=(), dtype=float32)\n",
      "Test ADE 3.8381659939945068\n",
      "Test Average FDE (Across  all samples) 4.754113051470588\n",
      "Test Min FDE 4.742509550206801\n",
      "Test Best ADE Loss So Far (N = 20) 3.8381659939945068\n",
      "Test Best Min FDE (N = 20) 4.742509550206801\n",
      "Test time error in destination best: 4.638 and mean: 4.650\n",
      "Test time error overall (ADE) best: 3.764\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 3.76 ########\n",
      "Train Loss tf.Tensor(686536.1, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(303278.22, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(205420.33, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(177837.53, shape=(), dtype=float32)\n",
      "Test ADE 3.764204954254807\n",
      "Test Average FDE (Across  all samples) 4.650478587431066\n",
      "Test Min FDE 4.637794763901654\n",
      "Test Best ADE Loss So Far (N = 20) 3.764204954254807\n",
      "Test Best Min FDE (N = 20) 4.637794763901654\n",
      "Test time error in destination best: 4.525 and mean: 4.539\n",
      "Test time error overall (ADE) best: 3.693\n",
      "Epoch:  0\n",
      "################## BEST PERFORMANCE 3.69 ########\n",
      "Train Loss tf.Tensor(672300.75, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(298084.62, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(197746.55, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(176469.56, shape=(), dtype=float32)\n",
      "Test ADE 3.6927200406246845\n",
      "Test Average FDE (Across  all samples) 4.539373061236213\n",
      "Test Min FDE 4.524883674172794\n",
      "Test Best ADE Loss So Far (N = 20) 3.6927200406246845\n",
      "Test Best Min FDE (N = 20) 4.524883674172794\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-68274d7e071c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-54-d4eab6a54a61>\u001b[0m in \u001b[0;36mrun_train\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m                 \u001b[0mtrajx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                 \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkld\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                 \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_point_loss_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_point_loss_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrajx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_of_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-52-327992a811a0>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(trajx, model, optimizer)\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mtape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mdest_rec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfuture_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[1;31m#print(f\"dest_recon {dest_recon}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[1;31m#print(f\"mu {mu}\")\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-49-ff072e87d625>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, dest)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mlatentDistributionDecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraj_past_ftr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m     \u001b[0mgenerated_dest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatentDistributionDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatentDistributionDecoder_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\module\\module.py\u001b[0m in \u001b[0;36mmethod_with_name_scope\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmethod_with_name_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_with_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-89abe66a2094>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-48-89abe66a2094>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mmatmul\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, name)\u001b[0m\n\u001b[0;32m   3698\u001b[0m             a, b, adj_x=adjoint_a, adj_y=adjoint_b, Tout=output_type, name=name)\n\u001b[0;32m   3699\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3700\u001b[1;33m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[0;32m   3701\u001b[0m             a, b, transpose_a=transpose_a, transpose_b=transpose_b, name=name)\n\u001b[0;32m   3702\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmat_mul\u001b[1;34m(a, b, transpose_a, transpose_b, name)\u001b[0m\n\u001b[0;32m   6010\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6011\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6012\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m   6013\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"MatMul\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_a\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"transpose_b\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6014\u001b[0m         transpose_b)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
