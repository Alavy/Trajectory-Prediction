{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import glob\n",
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "kld_reg= 1\n",
    "adl_reg=1\n",
    "\n",
    "fdim=16\n",
    "zdim=16\n",
    "sigma=1.3\n",
    "past_length=8\n",
    "future_length=12\n",
    "data_scale=1.86\n",
    "\n",
    "enc_past_size=(past_length*2,512,256,fdim)\n",
    "enc_dest_size=(2,8,16,fdim)\n",
    "\n",
    "enc_latent_size=(2*fdim,8,50,2*zdim)\n",
    "dec_size=(fdim + zdim,1024,512,1024,2)\n",
    "\n",
    "predictor_size=(2*fdim + 2,1024,512,256,2*(future_length-1))\n",
    "\n",
    "non_local_theta_size = (2*fdim + 2,256,128,64,128)\n",
    "non_local_phi_size=(2*fdim + 2,256,128,64,128)\n",
    "non_local_g_size=(2*fdim + 2,256,128,64,2*fdim + 2)\n",
    "nonlocal_pools=3\n",
    "learning_rate=0.0003"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData(file_path: str):\n",
    "  npz = np.load(file_path, allow_pickle=True)\n",
    "  return npz['observations'], npz['obs_speed'], npz['targets'], npz[\n",
    "      'target_speed'], npz['mean'], npz['std']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense(tf.Module):\n",
    "  def __init__(self, input_dim, output_size, name=None):\n",
    "    super(Dense, self).__init__(name=name)\n",
    "    self.w = tf.Variable(tf.random.uniform([input_dim, output_size],-(1.0/input_dim)**0.5,(1.0/input_dim)**0.5 ),name='w',dtype=tf.float32,trainable=True)\n",
    "    self.b = tf.Variable(tf.random.uniform([output_size],-(1.0/input_dim)**0.5,(1.0/input_dim)**0.5 ), name='b',dtype=tf.float32,trainable=True)\n",
    "  def __call__(self, x):\n",
    "    x = tf.constant(x,dtype=tf.float32)\n",
    "    y = tf.matmul(x, self.w) + self.b\n",
    "    return tf.nn.relu(y)\n",
    "\n",
    "class FullyConnectedNeuralNet(tf.Module):\n",
    "  def __init__(self,sizes, name=None):\n",
    "    super(FullyConnectedNeuralNet, self).__init__(name=name)\n",
    "    self.layers = []\n",
    "    with self.name_scope:\n",
    "      for i in range(len(sizes)-1):\n",
    "        self.layers.append(Dense(input_dim=sizes[i], output_size=sizes[i+1]))\n",
    "  @tf.Module.with_name_scope\n",
    "  def __call__(self, x):\n",
    "    for layer in self.layers:\n",
    "      x = layer(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MainModel(tf.Module):\n",
    "    def __init__(self,name=None):\n",
    "        super(MainModel, self).__init__(name=name)\n",
    "\n",
    "        self.zdim = zdim\n",
    "        self.sigma = sigma\n",
    "        self.nonlocal_pools = nonlocal_pools\n",
    "        \n",
    "\n",
    "\n",
    "        self.pastEncoder = FullyConnectedNeuralNet(enc_past_size)\n",
    "\n",
    "        self.destEncoder = FullyConnectedNeuralNet(enc_dest_size)\n",
    "\n",
    "        self.latentDistributionEncoder = FullyConnectedNeuralNet(enc_latent_size)\n",
    "\n",
    "        self.latentDistributionDecoder = FullyConnectedNeuralNet(dec_size)\n",
    "\n",
    "\n",
    "        self.nonLocalTheta = FullyConnectedNeuralNet(non_local_theta_size)\n",
    "        self.nonLocalPhi = FullyConnectedNeuralNet(non_local_phi_size)\n",
    "        self.nonLocalG = FullyConnectedNeuralNet(non_local_g_size)\n",
    "        \n",
    "        self.predictorNetwork = FullyConnectedNeuralNet(predictor_size)\n",
    "\n",
    "\n",
    "    def forward(self, x, initial_pos, dest=[], mask =[] ):\n",
    "\n",
    "        if len(dest):\n",
    "            self.training=True\n",
    "        else:\n",
    "            self.training=False\n",
    "        \n",
    "        # encode\n",
    "        traj_past_ftr = self.pastEncoder(x)\n",
    "        #print(f\"ftraj max {ftraj.numpy().max()}\")\n",
    "        if not self.training:\n",
    "            z = tf.random.normal((x.shape[0], self.zdim),0,self.sigma)\n",
    "\n",
    "        else:\n",
    "            dest_ftr = self.destEncoder(dest)\n",
    "            #print(f\"dest_features Max {dest_features.numpy().max()}\")\n",
    "\n",
    "            concat_ftr = tf.concat((traj_past_ftr, dest_ftr), axis = 1)\n",
    "            latent =  self.latentDistributionEncoder(concat_ftr)\n",
    "            mu = latent[:, 0:self.zdim] # 2-d array\n",
    "            logvar =  latent[:, self.zdim:] # 2-d array\n",
    "\n",
    "            var = tf.math.exp(logvar*0.5)\n",
    "            #print(f\"var {var}\")\n",
    "            eps = tf.random.normal(var.shape)\n",
    "            z = eps*var + mu\n",
    "            #print(f\"z -> {z}\")\n",
    "\n",
    "\n",
    "        latentDistributionDecoder_input = tf.concat((traj_past_ftr, z), axis = 1)\n",
    "        generated_dest = self.latentDistributionDecoder(latentDistributionDecoder_input)\n",
    "        #generated_dest = tf.where(tf.math.is_nan(generated_dest), tf.zeros_like(generated_dest), generated_dest)\n",
    "\n",
    "        if self.training:\n",
    "            generated_dest_ftr = self.destEncoder(generated_dest)\n",
    "            #generated_dest_ftr = tf.where(tf.math.is_nan(generated_dest_ftr), tf.zeros_like(generated_dest_ftr), generated_dest_ftr)\n",
    "            #print(f\"{ tf.math.reduce_any(tf.math.is_nan(generated_dest_ftr))}\")\n",
    "\n",
    "            prediction_ftr = tf.concat((traj_past_ftr, generated_dest_ftr,initial_pos), axis = 1)\n",
    "            for i in range(self.nonlocal_pools):\n",
    "                prediction_ftr = self.nonLocalSocialPooling(prediction_ftr, mask)\n",
    "            pred_future = self.predictorNetwork(prediction_ftr)\n",
    "        \n",
    "            return generated_dest, mu, logvar, pred_future\n",
    "        else:\n",
    "            return generated_dest\n",
    "    \n",
    "    def nonLocalSocialPooling(self, feat, mask):\n",
    "        # N,C\n",
    "        theta_x = self.nonLocalTheta(feat)\n",
    "        # C,N\n",
    "        phi_x = tf.transpose(self.nonLocalPhi(feat))\n",
    "\n",
    "        # f_ij = (theta_i)^T(phi_j), (N,N)\n",
    "        f = tf.matmul(theta_x , phi_x)\n",
    "\n",
    "        # f_weights_i =  exp(f_ij)/(\\sum_{j=1}^N exp(f_ij))\n",
    "        f_weights =tf.nn.softmax(f, axis = -1)\n",
    "        # setting weights of non neighbours to zero\n",
    "        f_weights = f_weights * mask\n",
    "        pooled_g = self.nonLocalG(feat)\n",
    "        \n",
    "        #print(f\"f_weights {f_weights.shape}\")\n",
    "        #print(f\"self.pooled_g(feat) {pooled_g.shape}\")\n",
    "        \n",
    "        # rescaling row weights to 1\n",
    "        f_weights = tf.math.l2_normalize(f_weights,axis=1)\n",
    "        #print(f\"f_weights {f_weights.shape}\")\n",
    "\n",
    "        # ith row of all_pooled_f = \\sum_{j=1}^N f_weights_i_j * g_row_j\n",
    "        pooled_f = tf.matmul(f_weights, pooled_g)\n",
    "\n",
    "        return pooled_f + feat\n",
    "\n",
    "    def predict(self, past, generated_dest, mask, initial_pos):\n",
    "        \n",
    "        traj_past_ftr = self.pastEncoder(past)\n",
    "        generated_dest_ftr = self.destEncoder(generated_dest)\n",
    "        prediction_ftr = tf.concat((traj_past_ftr, generated_dest_ftr,initial_pos), axis = 1)\n",
    "        for i in range(self.nonlocal_pools):\n",
    "            prediction_ftr = self.nonLocalSocialPooling(prediction_ftr, mask)   \n",
    "        future_traj = self.predictorNetwork(prediction_ftr)\n",
    "        return future_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss(dest, dest_rec, mean, log_var, future, future_rec):\n",
    "    \n",
    "    rcl = tf.math.reduce_mean(tf.keras.metrics.mean_squared_error(dest, dest_rec))\n",
    "    adl = tf.math.reduce_mean(tf.keras.metrics.mean_squared_error(future, future_rec))\n",
    "\n",
    "    kld = -0.5 * tf.math.reduce_sum(1 + log_var - mean**2 - tf.math.exp(log_var))\n",
    "\n",
    "    return rcl, kld, adl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_batch(X,batchSize):\n",
    "    start = random.randint(0, len(X)-batchSize)\n",
    "    return X[start:start+batchSize]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model,optimizer):\n",
    "    trajectory_batches,mask_batches,initial_pos_batches = loadDataSocial('./social_pool_data/train_all_512_0_100.pickle',set_name=\"train\")\n",
    "    \n",
    "    train_loss = 0\n",
    "    total_rcl, total_kld, total_adl = 0, 0, 0\n",
    "    \n",
    "    for i, (traj, mask, initial_pos) in enumerate(zip(trajectory_batches,mask_batches,initial_pos_batches)):\n",
    "        traj -= traj[:, :1, :]\n",
    "        traj *= data_scale\n",
    "        x = traj[:, :past_length, :]\n",
    "        y = traj[:, past_length:, :]\n",
    "\n",
    "        x = x.reshape(-1, x.shape[1]*x.shape[2]) # (x,y,x,y ... )\n",
    "        dest = y[:, -1, :]\n",
    "        future = y[:, :-1, :].reshape(y.shape[0],-1)\n",
    "        #x.astype(np.float64)\n",
    "        #print(f\"trajx-> {trajx.shape}\")\n",
    "        \n",
    "        #print(f\"X shape -> {x.shape}\")\n",
    "        #print(f\"initial_pos -> {initial_pos.shape}\")\n",
    "        #print(f\"dest shape -> {dest.shape}\")\n",
    "        #print(f\"mask shape -> {mask.shape}\")\n",
    "         \n",
    "        with tf.GradientTape() as tape:\n",
    "            x=tf.constant(x,dtype=tf.float32)\n",
    "            initial_pos=tf.constant(initial_pos,dtype=tf.float32)\n",
    "            dest=tf.constant(dest,dtype=tf.float32)\n",
    "\n",
    "            tape.watch(x)\n",
    "            tape.watch(initial_pos)\n",
    "            tape.watch(dest)\n",
    "\n",
    "            dest_rec, mu, var, future_rec = model.forward(x, initial_pos, dest=dest, mask=mask)\n",
    "            #print(f\"dest_recon {dest_recon}\")\n",
    "            #print(f\"mu {mu}\")\n",
    "            #print(f\"var {var}\")\n",
    "            #print(f\"interpolated_future {interpolated_future}\") \n",
    "            rcl, kld, adl = calculate_loss(dest, dest_rec, mu, var, future, future_rec)   \n",
    "            loss = rcl + kld * kld_reg + adl * adl_reg\n",
    "            #print(f\"loss -> {loss}\")\n",
    "        grad_sub = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grad_sub, model.trainable_variables))\n",
    "       \n",
    "                    \n",
    "        #print(f\"total Loss {loss}\")\n",
    "        #print(f\"rcl Loss {rcl}\")\n",
    "        #print(f\"kld Loss {kld}\")\n",
    "        #print(f\"adl Loss {adl}\")\n",
    "        train_loss+=loss\n",
    "        total_rcl+=rcl\n",
    "        total_kld+=kld\n",
    "        total_adl+=adl\n",
    "    return train_loss, total_rcl, total_kld, total_adl\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, best_of_n = 1):\n",
    "    trajectory_batches,mask_batches,initial_pos_batches = loadDataSocial('./social_pool_data/test_all_4096_0_100.pickle',set_name=\"test\")\n",
    "    for i, (traj, mask, initial_pos) in enumerate(zip(trajectory_batches,mask_batches,initial_pos_batches)):\n",
    "   \n",
    "        traj -= traj[:, :1, :]\n",
    "        traj *= data_scale\n",
    "        x = traj[:, :past_length,:]\n",
    "        y = traj[:, past_length:,:]\n",
    "\n",
    "        x = x.reshape(-1, x.shape[1]*x.shape[2])\n",
    "\n",
    "        dest = y[:, -1, :]\n",
    "    \n",
    "        destination_errors = []\n",
    "        dectination_recs = []\n",
    "    \n",
    "        for _ in range(best_of_n):\n",
    "            x=tf.constant(x,dtype=tf.float32)\n",
    "            initial_pos=tf.constant(initial_pos,dtype=tf.float32)\n",
    "            dest_rec = model.forward(x, initial_pos)\n",
    "            dectination_recs.append(np.array(dest_rec))\n",
    "\n",
    "            error = np.linalg.norm(dest_rec - dest, axis = 1)\n",
    "            destination_errors.append(error)\n",
    "\n",
    "        destination_errors = np.array(destination_errors)\n",
    "        dectination_recs = np.array(dectination_recs)\n",
    "        # average error\n",
    "        avg_dest_error = np.mean(destination_errors)\n",
    "\n",
    "        indices = np.argmin(destination_errors, axis = 0)\n",
    "\n",
    "        best_dest = dectination_recs[indices,np.arange(x.shape[0]),  :]\n",
    "\n",
    "        # taking the minimum error out of all guess\n",
    "        dest_error = np.mean(np.min(destination_errors, axis = 0))\n",
    "\n",
    "        future_dest = model.predict(x, best_dest, mask, initial_pos)\n",
    "        # final overall prediction\n",
    "        predicted_future = np.concatenate((future_dest, best_dest), axis = 1)\n",
    "        predicted_future = np.reshape(predicted_future, (-1, future_length, 2))\n",
    "        # ADE error\n",
    "        overall_error = np.mean(np.linalg.norm(y - predicted_future, axis = 2))\n",
    "\n",
    "        overall_error /= data_scale\n",
    "        dest_error /= data_scale\n",
    "        avg_dest_error /= data_scale\n",
    "        #print('Test time error in destination best: {:0.3f} and mean: {:0.3f}'.format(dest_error, avg_dest_error))\n",
    "        #print('Test time error overall (ADE) best: {:0.3f}'.format(overall_error))\n",
    "\n",
    "    return overall_error, dest_error, avg_dest_error\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_train():\n",
    "    epochs = 1000\n",
    "    batchSize=100\n",
    "    model=MainModel()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "    N=20\n",
    "    best_test_loss = 50 # start saving after this threshold\n",
    "    best_endpoint_loss = 50\n",
    "    for epo in range(epochs):\n",
    "        train_loss, rcl, kld, adl = train(model,optimizer)\n",
    "        test_loss, final_point_loss_best, final_point_loss_avg = test(model, best_of_n = N)\n",
    "                \n",
    "        if best_test_loss > test_loss:\n",
    "            print(\"Epoch: \", epo+1)\n",
    "            print('################## BEST PERFORMANCE {:0.2f} ########'.format(test_loss))\n",
    "            best_test_loss = test_loss\n",
    "        \n",
    "\n",
    "        if final_point_loss_best < best_endpoint_loss:\n",
    "            best_endpoint_loss = final_point_loss_best\n",
    "\n",
    "        print(\"Train Loss\", train_loss)\n",
    "        print(\"RCL\", rcl)\n",
    "        print(\"KLD\", kld)\n",
    "        print(\"ADL\", adl)\n",
    "        print(\"Test ADE\", test_loss)\n",
    "        print(\"Test Average FDE (Across  all samples)\", final_point_loss_avg)\n",
    "        print(\"Test Min FDE\", final_point_loss_best)\n",
    "        print(\"Test Best ADE Loss So Far (N = {})\".format(N), best_test_loss)\n",
    "        print(\"Test Best Min FDE (N = {})\".format(N), best_endpoint_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadDataSocial(load_name,set_name=\"train\", id=False):\n",
    "    \n",
    "    with open(load_name, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    traj, masks = data\n",
    "    traj_new = []\n",
    "\n",
    "    if id==False:\n",
    "        for t in traj:\n",
    "            t = np.array(t)\n",
    "            t = t[:,:,2:]\n",
    "            traj_new.append(t)\n",
    "            if set_name==\"train\":\n",
    "            #augment training set with reversed tracklets...\n",
    "                reverse_t = np.flip(t, axis=1).copy()\n",
    "                traj_new.append(reverse_t)\n",
    "    else:\n",
    "        for t in traj:\n",
    "            t = np.array(t)\n",
    "            traj_new.append(t)\n",
    "            if set_name==\"train\":\n",
    "                #augment training set with reversed tracklets...\n",
    "                reverse_t = np.flip(t, axis=1).copy()\n",
    "                traj_new.append(reverse_t)\n",
    "    masks_new = []\n",
    "    \n",
    "    for m in masks:\n",
    "        masks_new.append(m)\n",
    "        if set_name==\"train\":\n",
    "            #add second time for the reversed tracklets...\n",
    "            masks_new.append(m)\n",
    "\n",
    "    traj_new = np.array(traj_new)\n",
    "    masks_new = np.array(masks_new)\n",
    "    trajectory_batches = traj_new.copy()\n",
    "    mask_batches = masks_new.copy()\n",
    "    \n",
    "    initial_pos_batches = np.array(initial_pos(trajectory_batches)) # for relative positioning\n",
    "    return trajectory_batches,mask_batches,initial_pos_batches\n",
    "\n",
    "def initial_pos(traj_batches):\n",
    "    batches = []\n",
    "    for b in traj_batches:\n",
    "        starting_pos = b[:,7,:].copy()/1000 #starting pos is end of past, start of future. scaled down.\n",
    "        batches.append(starting_pos)\n",
    "    return batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1028-47f677a6bda1>:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  traj_new = np.array(traj_new)\n",
      "<ipython-input-1028-47f677a6bda1>:34: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  masks_new = np.array(masks_new)\n",
      "<ipython-input-1028-47f677a6bda1>:38: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  initial_pos_batches = np.array(initial_pos(trajectory_batches)) # for relative positioning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Loss tf.Tensor(3337951.8, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(2011317.4, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(111368.54, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(1215265.8, shape=(), dtype=float32)\n",
      "Test ADE 114.19229406678735\n",
      "Test Average FDE (Across  all samples) 136.68710031817037\n",
      "Test Min FDE 136.231198874853\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2518769.2, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1555919.0, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(6809.921, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(956040.5, shape=(), dtype=float32)\n",
      "Test ADE 108.00251576435394\n",
      "Test Average FDE (Across  all samples) 137.35932380922378\n",
      "Test Min FDE 136.87482444188927\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2494428.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1545725.0, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(1990.5817, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(946712.75, shape=(), dtype=float32)\n",
      "Test ADE 107.68167317514295\n",
      "Test Average FDE (Across  all samples) 136.69991441952286\n",
      "Test Min FDE 136.22073922106014\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2498446.2, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1550227.6, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(1541.0569, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(946677.75, shape=(), dtype=float32)\n",
      "Test ADE 106.93480619271935\n",
      "Test Average FDE (Across  all samples) 134.29178217405914\n",
      "Test Min FDE 133.78531343193464\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2466612.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1525403.1, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(1189.5098, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(940019.7, shape=(), dtype=float32)\n",
      "Test ADE 106.11771448728713\n",
      "Test Average FDE (Across  all samples) 133.76866002236642\n",
      "Test Min FDE 133.2614283407888\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2447940.8, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1511324.0, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(549.5591, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(936066.7, shape=(), dtype=float32)\n",
      "Test ADE 105.98370159648007\n",
      "Test Average FDE (Across  all samples) 133.22493850543935\n",
      "Test Min FDE 132.72962672736054\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2446515.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1510418.0, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(375.08023, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(935722.06, shape=(), dtype=float32)\n",
      "Test ADE 106.10786529779699\n",
      "Test Average FDE (Across  all samples) 133.4703342888945\n",
      "Test Min FDE 132.95265115717405\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2441934.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1506901.1, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(273.19186, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(934759.6, shape=(), dtype=float32)\n",
      "Test ADE 106.22684378257469\n",
      "Test Average FDE (Across  all samples) 133.5909443516885\n",
      "Test Min FDE 133.09320429319976\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2426377.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1506486.0, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(214.46999, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(919677.1, shape=(), dtype=float32)\n",
      "Test ADE 104.65161238628201\n",
      "Test Average FDE (Across  all samples) 134.01787050308718\n",
      "Test Min FDE 133.51748886928763\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2420082.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1503793.2, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(163.86963, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(916125.44, shape=(), dtype=float32)\n",
      "Test ADE 105.01218390273333\n",
      "Test Average FDE (Across  all samples) 134.22479937153477\n",
      "Test Min FDE 133.71879003381216\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2416792.2, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1501592.2, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(128.66208, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(915070.8, shape=(), dtype=float32)\n",
      "Test ADE 105.05817873141324\n",
      "Test Average FDE (Across  all samples) 134.6601342642179\n",
      "Test Min FDE 134.14615097866263\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2414172.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1499493.9, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(108.503174, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(914569.56, shape=(), dtype=float32)\n",
      "Test ADE 105.19278844867313\n",
      "Test Average FDE (Across  all samples) 134.59732711956065\n",
      "Test Min FDE 134.10305720503612\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2414546.5, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1500024.4, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(91.069435, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(914431.06, shape=(), dtype=float32)\n",
      "Test ADE 105.38739145850552\n",
      "Test Average FDE (Across  all samples) 134.96327554025956\n",
      "Test Min FDE 134.4706545593918\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2411690.8, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1497876.4, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(69.80055, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(913744.7, shape=(), dtype=float32)\n",
      "Test ADE 105.4333917614109\n",
      "Test Average FDE (Across  all samples) 135.04467215589298\n",
      "Test Min FDE 134.56886865759407\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2411946.2, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1498293.1, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(60.27539, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(913592.7, shape=(), dtype=float32)\n",
      "Test ADE 105.41649324552878\n",
      "Test Average FDE (Across  all samples) 135.23847518428678\n",
      "Test Min FDE 134.76690476940524\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2412398.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1498947.2, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(51.84326, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(913399.06, shape=(), dtype=float32)\n",
      "Test ADE 105.61309702856619\n",
      "Test Average FDE (Across  all samples) 135.5405007639239\n",
      "Test Min FDE 135.05340904317876\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n",
      "Train Loss tf.Tensor(2415026.0, shape=(), dtype=float32)\n",
      "RCL tf.Tensor(1498566.4, shape=(), dtype=float32)\n",
      "KLD tf.Tensor(92.52848, shape=(), dtype=float32)\n",
      "ADL tf.Tensor(916367.0, shape=(), dtype=float32)\n",
      "Test ADE 105.76161192558234\n",
      "Test Average FDE (Across  all samples) 135.5364563644573\n",
      "Test Min FDE 135.0548857001848\n",
      "Test Best ADE Loss So Far (N = 20) 50\n",
      "Test Best Min FDE (N = 20) 50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1029-68274d7e071c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrun_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-1027-2805ceeb0560>\u001b[0m in \u001b[0;36mrun_train\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkld\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mtest_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_point_loss_best\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_point_loss_avg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_of_n\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbest_test_loss\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1026-cffda072d265>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(model, best_of_n)\u001b[0m\n\u001b[0;32m     18\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0minitial_pos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0mdest_rec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minitial_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mdectination_recs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdest_rec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1022-1fe21e4accf4>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, initial_pos, dest, mask)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m         \u001b[0mlatentDistributionDecoder_input\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraj_past_ftr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 57\u001b[1;33m         \u001b[0mgenerated_dest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlatentDistributionDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlatentDistributionDecoder_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     58\u001b[0m         \u001b[1;31m#generated_dest = tf.where(tf.math.is_nan(generated_dest), tf.zeros_like(generated_dest), generated_dest)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\module\\module.py\u001b[0m in \u001b[0;36mmethod_with_name_scope\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmethod_with_name_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod_with_name_scope\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1021-9e4e84f22378>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     19\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1021-9e4e84f22378>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m      6\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m   1381\u001b[0m         \u001b[1;31m#   r_binary_op_wrapper use different force_same_dtype values.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmaybe_promote_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforce_same_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m         \u001b[1;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36mop_dispatch_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1094\u001b[0m       \u001b[1;31m# Fallback dispatch system (dispatch v1):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1095\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1096\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdispatch_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1097\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m         \u001b[1;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_add_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1735\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1736\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1737\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\AnacondaFiles\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36madd_v2\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m    459\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 461\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    462\u001b[0m         _ctx, \"AddV2\", name, x, y)\n\u001b[0;32m    463\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "run_train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
